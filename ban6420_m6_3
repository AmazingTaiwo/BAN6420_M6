import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

# Load the Fashion MNIST dataset
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Normalize the images to be between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

# Reshape the images to be 28x28x1 (for grayscale)
x_train = np.expand_dims(x_train, axis=-1)
x_test = np.expand_dims(x_test, axis=-1)

# Check the shape of the training data
print(f"Shape of training data: {x_train.shape}")

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)
datagen.fit(x_train)

# Initialize the model
model = models.Sequential()

# Layer 1: Convolutional Layer
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.BatchNormalization())

# Layer 2: Max Pooling Layer
model.add(layers.MaxPooling2D((2, 2)))

# Layer 3: Convolutional Layer
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.BatchNormalization())

# Layer 4: Max Pooling Layer
model.add(layers.MaxPooling2D((2, 2)))

# Layer 5: Convolutional Layer
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.BatchNormalization())

# Layer 6: Dropout to reduce overfitting
model.add(layers.Dropout(0.4))

# Layer 7: Flatten and Fully Connected Layer
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.BatchNormalization())

# Output Layer
model.add(layers.Dense(10, activation='softmax'))  # 10 classes for Fashion MNIST

# Compile the model with a lower learning rate for better convergence
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Early stopping and model checkpoint to prevent overfitting and save the best model
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_fashion_mnist_model.h5', monitor='val_accuracy', save_best_only=True)

# Train the model using data augmentation
history = model.fit(datagen.flow(x_train, y_train, batch_size=64),
                    epochs=20, validation_data=(x_test, y_test), 
                    callbacks=[early_stop, checkpoint])

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print(f"Test accuracy: {test_acc}")

# Make predictions on the test set
predictions = model.predict(x_test)

# Display the first five test images and their predictions
for i in range(5):
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {np.argmax(predictions[i])}, Actual: {y_test[i]}")
    plt.show()

# Save the trained model (if desired)
model.save('fashion_mnist_cnn_optimized.h5')

# Plotting training & validation accuracy and loss for better visualization
plt.figure(figsize=(12, 4))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Predicting on additional test images for more insight
additional_images = x_test[:5]
additional_predictions = model.predict(additional_images)
for i in range(5):
    plt.imshow(additional_images[i].reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {np.argmax(additional_predictions[i])}, Actual: {y_test[i]}")
    plt.show()
